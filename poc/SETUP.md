# Установка для POC тестирования

## Шаг 1: Установка Ollama

### Windows

1. Скачайте установщик с https://ollama.ai/download
2. Запустите установщик и следуйте инструкциям
3. После установки Ollama будет доступен в командной строке

### Проверка установки

```cmd
ollama --version
```

## Шаг 2: Запуск Ollama сервера

Откройте командную строку и запустите:

```cmd
ollama serve
```

Оставьте это окно открытым. Ollama будет работать в фоне.

## Шаг 3: Загрузка модели LLaVA

Откройте НОВОЕ окно командной строки и выполните:

```cmd
ollama pull llava:7b-v1.6-mistral-q4_0
```

Это загрузит ~4GB модели. Подождите завершения.

### Проверка модели

```cmd
ollama list
```

Вы должны увидеть `llava:7b-v1.6-mistral-q4_0` в списке.

## Шаг 4: Установка Python зависимостей

```cmd
cd poc
pip install -r requirements.txt
```

Это установит:
- PyTorch с CUDA
- YOLOv8
- EasyOCR
- Ollama Python client
- И другие зависимости

## Шаг 5: Подготовка тестового изображения

1. Сфотографируйте любое бытовое устройство:
   - Пульт от телевизора
   - Панель стиральной машины
   - Микроволновку
   - Кофеварку
   - Любое устройство с кнопками и текстом

2. Сохраните фото как `test_images/test_device.jpg`

**Требования к фото:**
- Хорошее освещение
- Четкое изображение (не размытое)
- Устройство занимает большую часть кадра
- Текст на кнопках читаем
- Формат: JPG или PNG

## Шаг 6: Запуск тестов

### Тест 1: LLaVA

```cmd
python test_ollama_llava.py
```

Проверяет:
- Работу Ollama
- Генерацию описаний на русском
- Время отклика

### Тест 2: YOLOv8n

```cmd
python test_yolo.py
```

Проверяет:
- Детекцию объектов
- Скорость на GPU
- Использование VRAM

### Тест 3: EasyOCR

```cmd
python test_easyocr.py
```

Проверяет:
- Распознавание текста
- Поддержку русского языка
- Качество OCR

### Тест 4: Интеграция

```cmd
python test_integration.py
```

Полный end-to-end тест всего pipeline.

## Ожидаемые результаты

✓ LLaVA отвечает на русском < 10 сек
✓ YOLO детектирует объекты < 100ms
✓ OCR распознает текст на кириллице
✓ Общее время < 15 сек
✓ VRAM < 3.5 GB

## Troubleshooting

### Ollama не запускается

- Проверьте что порт 11434 свободен
- Перезапустите Ollama: `ollama serve`

### CUDA не найдена

- Установите CUDA Toolkit 11.8+
- Проверьте: `nvidia-smi`
- Переустановите PyTorch с CUDA

### Модель не загружается

- Проверьте интернет соединение
- Освободите место на диске (нужно ~5GB)
- Попробуйте снова: `ollama pull llava:7b-v1.6-mistral-q4_0`

### Медленная работа

- Убедитесь что используется GPU, а не CPU
- Проверьте что другие программы не используют GPU
- Закройте браузер и другие приложения

### Плохое качество распознавания

- Используйте фото лучшего качества
- Улучшите освещение
- Сфотографируйте устройство ближе
- Убедитесь что текст четкий
